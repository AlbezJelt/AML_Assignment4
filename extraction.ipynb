{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "e7e0516000873b8822c2ba71d3dbcf32d17e959103f81c88a6217b70f2b31cea"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Extract the dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Download ed estrazione del dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "\n",
    "def extract_images(path):\n",
    "    for root, subdir, files in os.walk(img_path):\n",
    "        for f in files:\n",
    "            if '.jpg' in f:\n",
    "                return False\n",
    "    return True\n",
    "\n",
    "base_path = os.getcwd()\n",
    "img_path = os.path.join(base_path, 'tmp')\n",
    "\n",
    "if extract_images(img_path):\n",
    "\n",
    "    url = 'https://md-datasets-cache-zipfiles-prod.s3.eu-west-1.amazonaws.com/4drtyfjtfy-1.zip'\n",
    "    filename = url.split(\"/\")[-1]\n",
    "    file_path = os.path.join(img_path, filename)\n",
    "\n",
    "    if os.path.isfile(file_path) == False:\n",
    "        buffer_size = 1024\n",
    "        response = requests.get(url, stream=True)\n",
    "        file_size = int(response.headers.get(\"Content-Length\", 0))\n",
    "        progress = tqdm(response.iter_content(buffer_size), f\"Downloading {filename}\", total=file_size, unit=\"B\", unit_scale=True, unit_divisor=1024)\n",
    "        with open(file_path, \"wb\") as f:\n",
    "            for data in progress:\n",
    "                f.write(data)\n",
    "                progress.update(len(data))\n",
    "\n",
    "        with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(img_path)\n",
    "            os.remove(file_path)\n",
    "        \n",
    "        file_path = os.path.join(img_path, 'dataset2.zip')\n",
    "        with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(img_path)\n",
    "            os.remove(file_path)\n",
    "\n",
    "img_path = os.path.join(img_path, 'dataset2')"
   ]
  },
  {
   "source": [
    "## Load images"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Definiamo la funzione per importare il dataset scaricato.\n",
    "Questa prende in input il path della cartella contenete le immagini ed un modello Tensorflow che funge da encoder per eseguire feature extraction.\n",
    "Per ogni sample processato la classe viene dedotta dal nome del file."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "def prepare_targets(Y):\n",
    "\tle = preprocessing.LabelEncoder()\n",
    "\tle.fit(Y)\n",
    "\ty_enc = le.transform(Y)\n",
    "\treturn y_enc\n",
    "\n",
    "def import_data(path, keras_encoder):\n",
    "    x_list, y_list = [], []\n",
    "\n",
    "    files = os.listdir(path)\n",
    "    for f in tqdm(files):\n",
    "        if f.endswith('.jpg'):\n",
    "            file_path = os.path.normpath(os.path.join(path, f))\n",
    "            label = re.sub(r'\\d+', '', Path(file_path).stem) \n",
    "            x = np.expand_dims(\n",
    "                image.img_to_array(\n",
    "                    image.load_img(\n",
    "                        file_path, \n",
    "                        target_size=(224, 224)\n",
    "                        )\n",
    "                    ), \n",
    "                axis=0\n",
    "                )\n",
    "            x = preprocess_input(x)\n",
    "            x = model.predict(x)\n",
    "            x_list.append(x)\n",
    "            y_list.append(label)\n",
    "            \n",
    "            # Free memory\n",
    "            x = None            \n",
    "\n",
    "    Y = prepare_targets(np.array(y_list))\n",
    "\n",
    "    return np.vstack(x_list), Y"
   ]
  },
  {
   "source": [
    "## block5_pool"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58892288/58889256 [==============================] - 34s 1us/step\n",
      "100%|██████████| 1125/1125 [02:59<00:00,  6.28it/s]\n"
     ]
    }
   ],
   "source": [
    "model = VGG16(weights='imagenet', include_top=False)\n",
    "x, y = import_data(img_path, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the numpy array for future training\n",
    "from numpy import asarray\n",
    "from numpy import savez_compressed\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42)\n",
    "\n",
    "save_path = os.path.join(base_path, 'data', 'block5_pool')\n",
    "\n",
    "savez_compressed(os.path.join(save_path, 'x_train.npz'), x_train)\n",
    "savez_compressed(os.path.join(save_path, 'y_train.npz'), y_train)\n",
    "savez_compressed(os.path.join(save_path, 'x_test.npz'), x_test)\n",
    "savez_compressed(os.path.join(save_path, 'y_test.npz'), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Free up numpy array memory for further feature extration with different VGG16 cuts\n",
    "x, y, x_train, y_train, x_test, y_test = None, None, None, None, None, None"
   ]
  },
  {
   "source": [
    "## block4_pool"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
      "553467904/553467096 [==============================] - 345s 1us/step\n"
     ]
    }
   ],
   "source": [
    "# Load the complete VGG16 model\n",
    "from tensorflow.keras.models import Model\n",
    "base_model = VGG16(weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 0/1125 [00:00<?, ?it/s]Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "=================================================================\n",
      "Total params: 7,635,264\n",
      "Trainable params: 7,635,264\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "block4_pool - extracting features...\n",
      "100%|██████████| 1125/1125 [02:40<00:00,  7.01it/s]\n",
      "block4_pool - saving dataset...\n",
      "block4_pool - Done!\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs=base_model.input, outputs=base_model.get_layer('block4_pool').output)\n",
    "print(model.summary())\n",
    "print('block4_pool - extracting features...')\n",
    "x, y = import_data(img_path, model)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42)\n",
    "\n",
    "save_path = os.path.join(base_path, 'data', 'block4_pool')\n",
    "\n",
    "print('block4_pool - saving dataset...')\n",
    "savez_compressed(os.path.join(save_path, 'x_train.npz'), x_train)\n",
    "savez_compressed(os.path.join(save_path, 'y_train.npz'), y_train)\n",
    "savez_compressed(os.path.join(save_path, 'x_test.npz'), x_test)\n",
    "savez_compressed(os.path.join(save_path, 'y_test.npz'), y_test)\n",
    "print('block4_pool - Done!')\n",
    "\n",
    "x, y, x_train, y_train, x_test, y_test = None, None, None, None, None, None"
   ]
  },
  {
   "source": [
    "## block2_pool"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 1/1125 [00:00<01:58,  9.46it/s]Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "=================================================================\n",
      "Total params: 260,160\n",
      "Trainable params: 260,160\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "block2_pool - extracting features...\n",
      "100%|██████████| 1125/1125 [01:23<00:00, 13.44it/s]\n",
      "block2_pool - saving dataset...\n",
      "block2_pool - Done!\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs=base_model.input, outputs=base_model.get_layer('block2_pool').output)\n",
    "print(model.summary())\n",
    "print('block2_pool - extracting features...')\n",
    "x, y = import_data(img_path, model)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42)\n",
    "\n",
    "save_path = os.path.join(base_path, 'data', 'block2_pool')\n",
    "\n",
    "print('block2_pool - saving dataset...')\n",
    "savez_compressed(os.path.join(save_path, 'x_train.npz'), x_train)\n",
    "savez_compressed(os.path.join(save_path, 'y_train.npz'), y_train)\n",
    "savez_compressed(os.path.join(save_path, 'x_test.npz'), x_test)\n",
    "savez_compressed(os.path.join(save_path, 'y_test.npz'), y_test)\n",
    "print('block2_pool - Done!')\n",
    "\n",
    "x, y, x_train, y_train, x_test, y_test = None, None, None, None, None, None"
   ]
  }
 ]
}