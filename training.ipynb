{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "e7e0516000873b8822c2ba71d3dbcf32d17e959103f81c88a6217b70f2b31cea"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Training"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Per ogni dataset preprocessato viene allenato un classificatore XGBoost.\n",
    "Per trovare il modello migliore, rispetto ai possibili iperparametri impostabili, viene sfruttata una ricerca random con 10 iterazioni nello spazio degli iperparametri.\n",
    "Ogni modello viene valutato utilizzando cross validation a 5 fold, per un totale di 50 modelli allenati per dataset."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from modules.utils import load_train_ds\n",
    "from modules.utils import custom_flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb \n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "def xgb_cross_val(X, Y, iter, cv, njobs):\n",
    "    classifier = xgb.XGBClassifier()       \n",
    "    param_grid = {\n",
    "            #### Default model parameters ######\n",
    "            'objective' : ['multi:softmax'],\n",
    "            'eval_metric' : ['mlogloss'],\n",
    "            'num_classes': [4],\n",
    "            'random_state' : [42],\n",
    "            'verbosity' : [0],\n",
    "            ####################################\n",
    "            'max_depth': [25, 50, 75, 100],\n",
    "            'learning_rate': [0.001, 0.01, 0.1, 0.2, 0.3],\n",
    "            'subsample': [0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "            'colsample_bytree': [0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "            'colsample_bylevel': [0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "            'min_child_weight': [0.5, 1.0, 3.0, 5.0, 7.0, 10.0],\n",
    "            'gamma': [0, 0.25, 0.5, 1.0],\n",
    "            'reg_lambda': [0.1, 1.0, 5.0, 10.0, 50.0, 100.0],\n",
    "            'n_estimators': [100, 500, 1000]}\n",
    "\n",
    "    rs_clf = RandomizedSearchCV(classifier, \n",
    "                            param_grid, \n",
    "                            n_iter=iter,\n",
    "                            scoring='accuracy',\n",
    "                            n_jobs=njobs, \n",
    "                            verbose=5, \n",
    "                            cv=cv, \n",
    "                            random_state=42)\n",
    "\n",
    "    results = rs_clf.fit(x_train, y_train)\n",
    "    return results\n"
   ]
  },
  {
   "source": [
    "## \"block4_pool\""
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = os.path.join(\n",
    "    os.getcwd(),\n",
    "    'data',\n",
    "    'block4_pool')\n",
    "\n",
    "x_train, y_train = load_train_ds(dataset_path)\n",
    "x_train = custom_flatten(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done   8 tasks      | elapsed: 16.3min\n",
      "[Parallel(n_jobs=5)]: Done  50 out of  50 | elapsed: 160.4min finished\n"
     ]
    }
   ],
   "source": [
    "results = xgb_cross_val(x_train, y_train, 10, 5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the random search results\n",
    "# Refit is true so it also contains the best estimator\n",
    "with open(os.path.join(os.getcwd(), 'results', 'results_block4_pool'), 'wb') as f:\n",
    "    pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   verbosity  subsample  reg_lambda  random_state      objective  num_classes  \\\n",
       "0          0        0.9       100.0            42  multi:softmax            4   \n",
       "1          0        0.5         0.1            42  multi:softmax            4   \n",
       "2          0        0.9        10.0            42  multi:softmax            4   \n",
       "3          0        1.0        10.0            42  multi:softmax            4   \n",
       "4          0        0.5         0.1            42  multi:softmax            4   \n",
       "5          0        0.5         5.0            42  multi:softmax            4   \n",
       "6          0        1.0         0.1            42  multi:softmax            4   \n",
       "7          0        0.9         1.0            42  multi:softmax            4   \n",
       "8          0        0.5        10.0            42  multi:softmax            4   \n",
       "9          0        0.9        10.0            42  multi:softmax            4   \n",
       "\n",
       "   n_estimators  min_child_weight  max_depth  learning_rate  gamma  \\\n",
       "0           100               5.0         25          0.010   1.00   \n",
       "1          1000              10.0        100          0.300   1.00   \n",
       "2          1000               1.0         25          0.300   0.25   \n",
       "3           500               1.0         25          0.200   0.50   \n",
       "4           100               1.0         75          0.100   0.00   \n",
       "5           500              10.0         50          0.100   0.00   \n",
       "6          1000               1.0         25          0.100   0.00   \n",
       "7           100              10.0         75          0.001   0.25   \n",
       "8          1000               3.0        100          0.100   0.50   \n",
       "9           100               1.0         50          0.200   1.00   \n",
       "\n",
       "  eval_metric  colsample_bytree  colsample_bylevel  Accuracy  \n",
       "0    mlogloss               0.4                1.0  0.920124  \n",
       "1    mlogloss               0.4                1.0  0.949377  \n",
       "2    mlogloss               0.7                1.0  0.948071  \n",
       "3    mlogloss               0.8                0.8  0.954728  \n",
       "4    mlogloss               0.6                0.4  0.964053  \n",
       "5    mlogloss               0.4                0.6  0.961377  \n",
       "6    mlogloss               0.5                1.0  0.950728  \n",
       "7    mlogloss               0.6                0.8  0.932088  \n",
       "8    mlogloss               0.7                0.9  0.961377  \n",
       "9    mlogloss               0.4                0.7  0.948071  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>verbosity</th>\n      <th>subsample</th>\n      <th>reg_lambda</th>\n      <th>random_state</th>\n      <th>objective</th>\n      <th>num_classes</th>\n      <th>n_estimators</th>\n      <th>min_child_weight</th>\n      <th>max_depth</th>\n      <th>learning_rate</th>\n      <th>gamma</th>\n      <th>eval_metric</th>\n      <th>colsample_bytree</th>\n      <th>colsample_bylevel</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0.9</td>\n      <td>100.0</td>\n      <td>42</td>\n      <td>multi:softmax</td>\n      <td>4</td>\n      <td>100</td>\n      <td>5.0</td>\n      <td>25</td>\n      <td>0.010</td>\n      <td>1.00</td>\n      <td>mlogloss</td>\n      <td>0.4</td>\n      <td>1.0</td>\n      <td>0.920124</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0.5</td>\n      <td>0.1</td>\n      <td>42</td>\n      <td>multi:softmax</td>\n      <td>4</td>\n      <td>1000</td>\n      <td>10.0</td>\n      <td>100</td>\n      <td>0.300</td>\n      <td>1.00</td>\n      <td>mlogloss</td>\n      <td>0.4</td>\n      <td>1.0</td>\n      <td>0.949377</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0.9</td>\n      <td>10.0</td>\n      <td>42</td>\n      <td>multi:softmax</td>\n      <td>4</td>\n      <td>1000</td>\n      <td>1.0</td>\n      <td>25</td>\n      <td>0.300</td>\n      <td>0.25</td>\n      <td>mlogloss</td>\n      <td>0.7</td>\n      <td>1.0</td>\n      <td>0.948071</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>1.0</td>\n      <td>10.0</td>\n      <td>42</td>\n      <td>multi:softmax</td>\n      <td>4</td>\n      <td>500</td>\n      <td>1.0</td>\n      <td>25</td>\n      <td>0.200</td>\n      <td>0.50</td>\n      <td>mlogloss</td>\n      <td>0.8</td>\n      <td>0.8</td>\n      <td>0.954728</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0.5</td>\n      <td>0.1</td>\n      <td>42</td>\n      <td>multi:softmax</td>\n      <td>4</td>\n      <td>100</td>\n      <td>1.0</td>\n      <td>75</td>\n      <td>0.100</td>\n      <td>0.00</td>\n      <td>mlogloss</td>\n      <td>0.6</td>\n      <td>0.4</td>\n      <td>0.964053</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0</td>\n      <td>0.5</td>\n      <td>5.0</td>\n      <td>42</td>\n      <td>multi:softmax</td>\n      <td>4</td>\n      <td>500</td>\n      <td>10.0</td>\n      <td>50</td>\n      <td>0.100</td>\n      <td>0.00</td>\n      <td>mlogloss</td>\n      <td>0.4</td>\n      <td>0.6</td>\n      <td>0.961377</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0</td>\n      <td>1.0</td>\n      <td>0.1</td>\n      <td>42</td>\n      <td>multi:softmax</td>\n      <td>4</td>\n      <td>1000</td>\n      <td>1.0</td>\n      <td>25</td>\n      <td>0.100</td>\n      <td>0.00</td>\n      <td>mlogloss</td>\n      <td>0.5</td>\n      <td>1.0</td>\n      <td>0.950728</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0</td>\n      <td>0.9</td>\n      <td>1.0</td>\n      <td>42</td>\n      <td>multi:softmax</td>\n      <td>4</td>\n      <td>100</td>\n      <td>10.0</td>\n      <td>75</td>\n      <td>0.001</td>\n      <td>0.25</td>\n      <td>mlogloss</td>\n      <td>0.6</td>\n      <td>0.8</td>\n      <td>0.932088</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0</td>\n      <td>0.5</td>\n      <td>10.0</td>\n      <td>42</td>\n      <td>multi:softmax</td>\n      <td>4</td>\n      <td>1000</td>\n      <td>3.0</td>\n      <td>100</td>\n      <td>0.100</td>\n      <td>0.50</td>\n      <td>mlogloss</td>\n      <td>0.7</td>\n      <td>0.9</td>\n      <td>0.961377</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0</td>\n      <td>0.9</td>\n      <td>10.0</td>\n      <td>42</td>\n      <td>multi:softmax</td>\n      <td>4</td>\n      <td>100</td>\n      <td>1.0</td>\n      <td>50</td>\n      <td>0.200</td>\n      <td>1.00</td>\n      <td>mlogloss</td>\n      <td>0.4</td>\n      <td>0.7</td>\n      <td>0.948071</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "pd.concat([pd.DataFrame(results.cv_results_[\"params\"]),pd.DataFrame(results.cv_results_[\"mean_test_score\"], columns=[\"Accuracy\"])],axis=1)"
   ]
  },
  {
   "source": [
    "## block5_pool"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = os.path.join(\n",
    "    os.getcwd(),\n",
    "    'data',\n",
    "    'block5_pool')\n",
    "\n",
    "x_train, y_train = load_train_ds(dataset_path)\n",
    "x_train = custom_flatten(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done  42 out of  50 | elapsed: 49.5min remaining:  9.4min\n",
      "[Parallel(n_jobs=10)]: Done  50 out of  50 | elapsed: 55.7min finished\n"
     ]
    }
   ],
   "source": [
    "results = xgb_cross_val(x_train, y_train, 10, 5, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(os.getcwd(), 'results_block5_pool'), 'wb') as f:\n",
    "    pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   verbosity  subsample  reg_lambda  random_state      objective  num_classes  \\\n",
       "0          0        0.9       100.0            42  multi:softmax            4   \n",
       "1          0        0.5         0.1            42  multi:softmax            4   \n",
       "2          0        0.9        10.0            42  multi:softmax            4   \n",
       "3          0        1.0        10.0            42  multi:softmax            4   \n",
       "4          0        0.5         0.1            42  multi:softmax            4   \n",
       "5          0        0.5         5.0            42  multi:softmax            4   \n",
       "6          0        1.0         0.1            42  multi:softmax            4   \n",
       "7          0        0.9         1.0            42  multi:softmax            4   \n",
       "8          0        0.5        10.0            42  multi:softmax            4   \n",
       "9          0        0.9        10.0            42  multi:softmax            4   \n",
       "\n",
       "   n_estimators  min_child_weight  max_depth  learning_rate  gamma  \\\n",
       "0           100               5.0         25          0.010   1.00   \n",
       "1          1000              10.0        100          0.300   1.00   \n",
       "2          1000               1.0         25          0.300   0.25   \n",
       "3           500               1.0         25          0.200   0.50   \n",
       "4           100               1.0         75          0.100   0.00   \n",
       "5           500              10.0         50          0.100   0.00   \n",
       "6          1000               1.0         25          0.100   0.00   \n",
       "7           100              10.0         75          0.001   0.25   \n",
       "8          1000               3.0        100          0.100   0.50   \n",
       "9           100               1.0         50          0.200   1.00   \n",
       "\n",
       "  eval_metric  colsample_bytree  colsample_bylevel  Accuracy  \n",
       "0    mlogloss               0.4                1.0  0.906799  \n",
       "1    mlogloss               0.4                1.0  0.942737  \n",
       "2    mlogloss               0.7                1.0  0.941413  \n",
       "3    mlogloss               0.8                0.8  0.937404  \n",
       "4    mlogloss               0.6                0.4  0.956044  \n",
       "5    mlogloss               0.4                0.6  0.936088  \n",
       "6    mlogloss               0.5                1.0  0.941413  \n",
       "7    mlogloss               0.6                0.8  0.909475  \n",
       "8    mlogloss               0.7                0.9  0.946746  \n",
       "9    mlogloss               0.4                0.7  0.946728  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>verbosity</th>\n      <th>subsample</th>\n      <th>reg_lambda</th>\n      <th>random_state</th>\n      <th>objective</th>\n      <th>num_classes</th>\n      <th>n_estimators</th>\n      <th>min_child_weight</th>\n      <th>max_depth</th>\n      <th>learning_rate</th>\n      <th>gamma</th>\n      <th>eval_metric</th>\n      <th>colsample_bytree</th>\n      <th>colsample_bylevel</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0.9</td>\n      <td>100.0</td>\n      <td>42</td>\n      <td>multi:softmax</td>\n      <td>4</td>\n      <td>100</td>\n      <td>5.0</td>\n      <td>25</td>\n      <td>0.010</td>\n      <td>1.00</td>\n      <td>mlogloss</td>\n      <td>0.4</td>\n      <td>1.0</td>\n      <td>0.906799</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0.5</td>\n      <td>0.1</td>\n      <td>42</td>\n      <td>multi:softmax</td>\n      <td>4</td>\n      <td>1000</td>\n      <td>10.0</td>\n      <td>100</td>\n      <td>0.300</td>\n      <td>1.00</td>\n      <td>mlogloss</td>\n      <td>0.4</td>\n      <td>1.0</td>\n      <td>0.942737</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0.9</td>\n      <td>10.0</td>\n      <td>42</td>\n      <td>multi:softmax</td>\n      <td>4</td>\n      <td>1000</td>\n      <td>1.0</td>\n      <td>25</td>\n      <td>0.300</td>\n      <td>0.25</td>\n      <td>mlogloss</td>\n      <td>0.7</td>\n      <td>1.0</td>\n      <td>0.941413</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>1.0</td>\n      <td>10.0</td>\n      <td>42</td>\n      <td>multi:softmax</td>\n      <td>4</td>\n      <td>500</td>\n      <td>1.0</td>\n      <td>25</td>\n      <td>0.200</td>\n      <td>0.50</td>\n      <td>mlogloss</td>\n      <td>0.8</td>\n      <td>0.8</td>\n      <td>0.937404</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0.5</td>\n      <td>0.1</td>\n      <td>42</td>\n      <td>multi:softmax</td>\n      <td>4</td>\n      <td>100</td>\n      <td>1.0</td>\n      <td>75</td>\n      <td>0.100</td>\n      <td>0.00</td>\n      <td>mlogloss</td>\n      <td>0.6</td>\n      <td>0.4</td>\n      <td>0.956044</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0</td>\n      <td>0.5</td>\n      <td>5.0</td>\n      <td>42</td>\n      <td>multi:softmax</td>\n      <td>4</td>\n      <td>500</td>\n      <td>10.0</td>\n      <td>50</td>\n      <td>0.100</td>\n      <td>0.00</td>\n      <td>mlogloss</td>\n      <td>0.4</td>\n      <td>0.6</td>\n      <td>0.936088</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0</td>\n      <td>1.0</td>\n      <td>0.1</td>\n      <td>42</td>\n      <td>multi:softmax</td>\n      <td>4</td>\n      <td>1000</td>\n      <td>1.0</td>\n      <td>25</td>\n      <td>0.100</td>\n      <td>0.00</td>\n      <td>mlogloss</td>\n      <td>0.5</td>\n      <td>1.0</td>\n      <td>0.941413</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0</td>\n      <td>0.9</td>\n      <td>1.0</td>\n      <td>42</td>\n      <td>multi:softmax</td>\n      <td>4</td>\n      <td>100</td>\n      <td>10.0</td>\n      <td>75</td>\n      <td>0.001</td>\n      <td>0.25</td>\n      <td>mlogloss</td>\n      <td>0.6</td>\n      <td>0.8</td>\n      <td>0.909475</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0</td>\n      <td>0.5</td>\n      <td>10.0</td>\n      <td>42</td>\n      <td>multi:softmax</td>\n      <td>4</td>\n      <td>1000</td>\n      <td>3.0</td>\n      <td>100</td>\n      <td>0.100</td>\n      <td>0.50</td>\n      <td>mlogloss</td>\n      <td>0.7</td>\n      <td>0.9</td>\n      <td>0.946746</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0</td>\n      <td>0.9</td>\n      <td>10.0</td>\n      <td>42</td>\n      <td>multi:softmax</td>\n      <td>4</td>\n      <td>100</td>\n      <td>1.0</td>\n      <td>50</td>\n      <td>0.200</td>\n      <td>1.00</td>\n      <td>mlogloss</td>\n      <td>0.4</td>\n      <td>0.7</td>\n      <td>0.946728</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "pd.concat([pd.DataFrame(results.cv_results_[\"params\"]),pd.DataFrame(results.cv_results_[\"mean_test_score\"], columns=[\"Accuracy\"])],axis=1)"
   ]
  },
  {
   "source": [
    "## block2_pool"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = os.path.join(\n",
    "    os.getcwd(),\n",
    "    'data',\n",
    "    'block2_pool')\n",
    "\n",
    "x_train, y_train = load_train_ds(dataset_path)\n",
    "x_train = custom_flatten(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed: 1014.5min finished\n"
     ]
    }
   ],
   "source": [
    "results = xgb_cross_val(x_train, y_train, 10, 5, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(os.getcwd(), 'results', 'results_block2_pool'), 'wb') as f:\n",
    "    pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   verbosity  subsample  reg_lambda  random_state      objective  num_classes  \\\n",
       "0          0        0.9       100.0            42  multi:softmax            4   \n",
       "1          0        0.5         0.1            42  multi:softmax            4   \n",
       "2          0        0.9        10.0            42  multi:softmax            4   \n",
       "3          0        1.0        10.0            42  multi:softmax            4   \n",
       "4          0        0.5         0.1            42  multi:softmax            4   \n",
       "5          0        0.5         5.0            42  multi:softmax            4   \n",
       "6          0        1.0         0.1            42  multi:softmax            4   \n",
       "7          0        0.9         1.0            42  multi:softmax            4   \n",
       "8          0        0.5        10.0            42  multi:softmax            4   \n",
       "9          0        0.9        10.0            42  multi:softmax            4   \n",
       "\n",
       "   n_estimators  min_child_weight  max_depth  learning_rate  gamma  \\\n",
       "0           100               5.0         25          0.010   1.00   \n",
       "1          1000              10.0        100          0.300   1.00   \n",
       "2          1000               1.0         25          0.300   0.25   \n",
       "3           500               1.0         25          0.200   0.50   \n",
       "4           100               1.0         75          0.100   0.00   \n",
       "5           500              10.0         50          0.100   0.00   \n",
       "6          1000               1.0         25          0.100   0.00   \n",
       "7           100              10.0         75          0.001   0.25   \n",
       "8          1000               3.0        100          0.100   0.50   \n",
       "9           100               1.0         50          0.200   1.00   \n",
       "\n",
       "  eval_metric  colsample_bytree  colsample_bylevel  Accuracy  \n",
       "0    mlogloss               0.4                1.0  0.900150  \n",
       "1    mlogloss               0.4                1.0  0.925448  \n",
       "2    mlogloss               0.7                1.0  0.928088  \n",
       "3    mlogloss               0.8                0.8  0.918790  \n",
       "4    mlogloss               0.6                0.4  0.938764  \n",
       "5    mlogloss               0.4                0.6  0.942755  \n",
       "6    mlogloss               0.5                1.0  0.921466  \n",
       "7    mlogloss               0.6                0.8  0.904168  \n",
       "8    mlogloss               0.7                0.9  0.934773  \n",
       "9    mlogloss               0.4                0.7  0.922781  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>verbosity</th>\n      <th>subsample</th>\n      <th>reg_lambda</th>\n      <th>random_state</th>\n      <th>objective</th>\n      <th>num_classes</th>\n      <th>n_estimators</th>\n      <th>min_child_weight</th>\n      <th>max_depth</th>\n      <th>learning_rate</th>\n      <th>gamma</th>\n      <th>eval_metric</th>\n      <th>colsample_bytree</th>\n      <th>colsample_bylevel</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0.9</td>\n      <td>100.0</td>\n      <td>42</td>\n      <td>multi:softmax</td>\n      <td>4</td>\n      <td>100</td>\n      <td>5.0</td>\n      <td>25</td>\n      <td>0.010</td>\n      <td>1.00</td>\n      <td>mlogloss</td>\n      <td>0.4</td>\n      <td>1.0</td>\n      <td>0.900150</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0.5</td>\n      <td>0.1</td>\n      <td>42</td>\n      <td>multi:softmax</td>\n      <td>4</td>\n      <td>1000</td>\n      <td>10.0</td>\n      <td>100</td>\n      <td>0.300</td>\n      <td>1.00</td>\n      <td>mlogloss</td>\n      <td>0.4</td>\n      <td>1.0</td>\n      <td>0.925448</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0.9</td>\n      <td>10.0</td>\n      <td>42</td>\n      <td>multi:softmax</td>\n      <td>4</td>\n      <td>1000</td>\n      <td>1.0</td>\n      <td>25</td>\n      <td>0.300</td>\n      <td>0.25</td>\n      <td>mlogloss</td>\n      <td>0.7</td>\n      <td>1.0</td>\n      <td>0.928088</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>1.0</td>\n      <td>10.0</td>\n      <td>42</td>\n      <td>multi:softmax</td>\n      <td>4</td>\n      <td>500</td>\n      <td>1.0</td>\n      <td>25</td>\n      <td>0.200</td>\n      <td>0.50</td>\n      <td>mlogloss</td>\n      <td>0.8</td>\n      <td>0.8</td>\n      <td>0.918790</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0.5</td>\n      <td>0.1</td>\n      <td>42</td>\n      <td>multi:softmax</td>\n      <td>4</td>\n      <td>100</td>\n      <td>1.0</td>\n      <td>75</td>\n      <td>0.100</td>\n      <td>0.00</td>\n      <td>mlogloss</td>\n      <td>0.6</td>\n      <td>0.4</td>\n      <td>0.938764</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0</td>\n      <td>0.5</td>\n      <td>5.0</td>\n      <td>42</td>\n      <td>multi:softmax</td>\n      <td>4</td>\n      <td>500</td>\n      <td>10.0</td>\n      <td>50</td>\n      <td>0.100</td>\n      <td>0.00</td>\n      <td>mlogloss</td>\n      <td>0.4</td>\n      <td>0.6</td>\n      <td>0.942755</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0</td>\n      <td>1.0</td>\n      <td>0.1</td>\n      <td>42</td>\n      <td>multi:softmax</td>\n      <td>4</td>\n      <td>1000</td>\n      <td>1.0</td>\n      <td>25</td>\n      <td>0.100</td>\n      <td>0.00</td>\n      <td>mlogloss</td>\n      <td>0.5</td>\n      <td>1.0</td>\n      <td>0.921466</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0</td>\n      <td>0.9</td>\n      <td>1.0</td>\n      <td>42</td>\n      <td>multi:softmax</td>\n      <td>4</td>\n      <td>100</td>\n      <td>10.0</td>\n      <td>75</td>\n      <td>0.001</td>\n      <td>0.25</td>\n      <td>mlogloss</td>\n      <td>0.6</td>\n      <td>0.8</td>\n      <td>0.904168</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0</td>\n      <td>0.5</td>\n      <td>10.0</td>\n      <td>42</td>\n      <td>multi:softmax</td>\n      <td>4</td>\n      <td>1000</td>\n      <td>3.0</td>\n      <td>100</td>\n      <td>0.100</td>\n      <td>0.50</td>\n      <td>mlogloss</td>\n      <td>0.7</td>\n      <td>0.9</td>\n      <td>0.934773</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0</td>\n      <td>0.9</td>\n      <td>10.0</td>\n      <td>42</td>\n      <td>multi:softmax</td>\n      <td>4</td>\n      <td>100</td>\n      <td>1.0</td>\n      <td>50</td>\n      <td>0.200</td>\n      <td>1.00</td>\n      <td>mlogloss</td>\n      <td>0.4</td>\n      <td>0.7</td>\n      <td>0.922781</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "pd.concat([pd.DataFrame(results.cv_results_[\"params\"]),pd.DataFrame(results.cv_results_[\"mean_test_score\"], columns=[\"Accuracy\"])],axis=1)"
   ]
  }
 ]
}