{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('AML_Assignment4': pipenv)",
   "metadata": {
    "interpreter": {
     "hash": "91c22b36c67837e6b74ced973920f404ca91cf29e050f8dae6e1b140f061535b"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Extract the dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "def extract_images(path):\n",
    "    for root, subdir, files in os.walk(img_path):\n",
    "        for f in files:\n",
    "            if '.jpg' in f:\n",
    "                return False\n",
    "    return True\n",
    "\n",
    "\n",
    "base_path = os.getcwd()\n",
    "img_path = f\"{base_path}/data/intel_image_classification\"\n",
    "\n",
    "if extract_images(img_path):\n",
    "    with zipfile.ZipFile(f\"{base_path}/data/archive.zip\", 'r') as zip_ref:\n",
    "        zip_ref.extractall(img_path)\n",
    "        # We are only interested on model performance, so no prediction data is used\n",
    "        shutil.rmtree(f\"{img_path}/seg_pred\")"
   ]
  },
  {
   "source": [
    "# Load images"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def prepare_targets(y_train, y_test):\n",
    "\tle = preprocessing.LabelEncoder()\n",
    "\tle.fit(y_train)\n",
    "\ty_train_enc = le.transform(y_train)\n",
    "\ty_test_enc = le.transform(y_test)\n",
    "\treturn y_train_enc, y_test_enc\n",
    "\n",
    "def import_data(path, keras_encoder):\n",
    "    x_train_list, y_train_list, x_test_list, y_test_list = [], [], [], []\n",
    "\n",
    "    for root, subdir, files in os.walk(img_path):\n",
    "            if len(files) < 2:\n",
    "                continue\n",
    "            for f in tqdm(files):\n",
    "                if f.endswith('.jpg'):\n",
    "                    file_path = os.path.normpath(os.path.join(root, f))\n",
    "                    label = file_path.split(os.sep)[len(file_path.split(os.sep)) - 2]\n",
    "                    x = np.expand_dims(\n",
    "                        image.img_to_array(\n",
    "                            image.load_img(\n",
    "                                file_path, \n",
    "                                target_size=(224, 224)\n",
    "                                )\n",
    "                            ), \n",
    "                        axis=0\n",
    "                        )\n",
    "                    x = preprocess_input(x)\n",
    "                    x = model.predict(x)\n",
    "                    if 'seg_train' in file_path:\n",
    "                        x_train_list.append(x)\n",
    "                        y_train_list.append(label)\n",
    "                    else:\n",
    "                        x_test_list.append(x)\n",
    "                        y_test_list.append(label)\n",
    "                    \n",
    "                    # Free memory\n",
    "                    x = None\n",
    "\n",
    "    y_train, y_test = prepare_targets(\n",
    "        np.array(y_train_list),\n",
    "        np.array(y_test_list)\n",
    "        )\n",
    "\n",
    "    return (np.vstack(x_train_list), y_train), (np.vstack(x_test_list), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 2404/2404 [06:45<00:00,  5.93it/s]\n",
      "100%|██████████| 2274/2274 [06:23<00:00,  5.93it/s]\n",
      "100%|██████████| 2512/2512 [07:02<00:00,  5.94it/s]\n",
      "100%|██████████| 2382/2382 [06:35<00:00,  6.02it/s]\n",
      "100%|██████████| 2271/2271 [06:04<00:00,  6.22it/s]\n",
      "100%|██████████| 2191/2191 [05:51<00:00,  6.23it/s]\n",
      "100%|██████████| 553/553 [01:28<00:00,  6.23it/s]\n",
      "100%|██████████| 510/510 [01:21<00:00,  6.25it/s]\n",
      "100%|██████████| 525/525 [01:24<00:00,  6.23it/s]\n",
      "100%|██████████| 501/501 [01:20<00:00,  6.23it/s]\n",
      "100%|██████████| 474/474 [01:16<00:00,  6.23it/s]\n",
      "100%|██████████| 437/437 [01:10<00:00,  6.22it/s]\n"
     ]
    }
   ],
   "source": [
    "model = VGG16(weights='imagenet', include_top=False)\n",
    "(x_train, y_train), (x_test, y_test) = import_data(img_path, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the numpy array for future training\n",
    "from numpy import asarray\n",
    "from numpy import savez_compressed\n",
    "\n",
    "save_path = f\"{base_path}/fe_data/include_top_false\"\n",
    "\n",
    "savez_compressed(f\"{save_path}/x_train.npz\", x_train)\n",
    "savez_compressed(f\"{save_path}/y_train.npz\", y_train)\n",
    "savez_compressed(f\"{save_path}/x_test.npz\", x_test)\n",
    "savez_compressed(f\"{save_path}/y_test.npz\", y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Free up numpy array memory for further feature extration with different VGG16 cuts\n",
    "x_train, y_train, x_test, y_test = None, None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "A local file was found, but it seems to be incomplete or outdated because the auto file hash does not match the original value of 64373286793e3c8b2b4e3219cbf3544b so we will re-download the data.\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
      "553467904/553467096 [==============================] - 361s 1us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "base_model = VGG16(weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"functional_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n_________________________________________________________________\nblock1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n_________________________________________________________________\nblock1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n_________________________________________________________________\nblock1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n_________________________________________________________________\nblock2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n_________________________________________________________________\nblock2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n_________________________________________________________________\nblock2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n_________________________________________________________________\nblock3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n_________________________________________________________________\nblock3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n_________________________________________________________________\nblock3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n_________________________________________________________________\nblock3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n_________________________________________________________________\nblock4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n_________________________________________________________________\nblock4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n_________________________________________________________________\nblock4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n_________________________________________________________________\nblock4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n=================================================================\nTotal params: 7,635,264\nTrainable params: 7,635,264\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs=base_model.input, outputs=base_model.get_layer('block4_pool').output)\n",
    "(x_train, y_train), (x_test, y_test) = import_data(img_path, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}